{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94a9560",
   "metadata": {},
   "source": [
    "# Dataset: Imagenet 1000\n",
    "\n",
    "### - Use pretrained models in the Keras Applications for applications: prediction, fine-tuning\n",
    "### - models: ResNet50, VGG16, VGG19\n",
    "### - Reference: https://keras.io/api/applications/ \n",
    " - imagenet 1000 class list: \n",
    "     [keras-imagenet_class_index.json](https://github.com/raghakot/keras-vis/blob/master/resources/imagenet_class_index.json),\n",
    "     [Class ID-Class Name Table](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/),                                  [clsidx_to_lables.txt](https://gist.github.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57)\n",
    " \n",
    " - imagenet-1k Dataset card: https://huggingface.co/datasets/imagenet-1k\n",
    " - image-net.org: https://www.image-net.org/update-mar-11-2021.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import applications \n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67317cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to download models from huggingface, it is necessary to set the following proxy and ssl \n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# suwon\n",
    "import os\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = '/etc/ssl/certs/ca-certificates.crt'\n",
    "os.environ['HTTP_PROXY'] ='http://75.17.107.42:8080'\n",
    "os.environ['HTTPS_PROXY'] ='http://75.17.107.42:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image from url\n",
    "import urllib\n",
    "from io import BytesIO\n",
    "\n",
    "def load_image_url(URL):\n",
    "    with urllib.request.urlopen(URL) as url:\n",
    "        img = keras.preprocessing.image.load_img(BytesIO(url.read()), target_size=(224, 224))\n",
    "\n",
    "    return img\n",
    "    # return image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b28af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv1 = applications.MobileNet(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56280cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv1.summary()\n",
    "keras.utils.plot_model(mobilenetv1, to_file=\"mobilenetv1.png\", show_shapes=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1872eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2 = applications.MobileNetV2(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2.summary()\n",
    "keras.utils.plot_model(mobilenetv2, to_file=\"mobilenetv2.png\", show_shapes=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from an image in the local directory\n",
    "img_file = img_path + 'elephant.jpg'\n",
    "img = image.load_img(img_file, target_size=(224, 224)) # Loads an image into PIL format\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "x = image.img_to_array(img) # PIL image into numpy array 224x224x3 (float32)\n",
    "x = np.expand_dims(x, axis=0) # batch form by adding axis: 224x224x3 into (1x224x224x3)\n",
    "x = preprocess_input(x) # substract mean values in [R, G, B]\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f14e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = 'https://d1bg8rd1h4dvdb.cloudfront.net/img/storypick/monamipet/2019/01/1811_pet_dog_pomeranian_m_01.jpg'\n",
    "a_img = load_image_url(img_url)\n",
    "plt.imshow(a_img)\n",
    "plt.axis('off')\n",
    "\n",
    "x = image.img_to_array(a_img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98136b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, to_file=\"resnet50.png\", show_shapes=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabf780",
   "metadata": {},
   "source": [
    "### Extract features with VGG16\n",
    "- include_top=False: makes the last pooling layer the output layer (just before last FCs and softmax layers)\n",
    "- cf. [vgg16 ref code](https://github.com/fchollet/deep-learning-models/blob/master/vgg16.py)\n",
    "- you may compare the model summary by setting include_top=False and include_top=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3be4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# include_top=False: excludes last FCs and softmax layers \n",
    "model = VGG16(weights='imagenet', include_top=False) \n",
    "\n",
    "img_file = img_path + 'elephant.jpg'\n",
    "img = image.load_img(img_file, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, to_file=\"vgg16.png\", show_shapes=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc82fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2250f7e",
   "metadata": {},
   "source": [
    "### Extract features from an arbitrary intermediate layer with VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "img_file = img_path + 'elephant.jpg'\n",
    "img = image.load_img(img_file, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "block4_pool_features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fcf361",
   "metadata": {},
   "outputs": [],
   "source": [
    "block4_pool_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770eff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(base_model, to_file=\"vgg19_base.png\", show_shapes=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06415715",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, to_file=\"vgg19_block4.png\", show_shapes=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e9b8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

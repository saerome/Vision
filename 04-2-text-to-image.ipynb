{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Image Generation using Stable Diffusion\n",
    "- huggingface, pytorch 사용\n",
    "- 참조\n",
    "  * https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview\n",
    "  * https://huggingface.co/docs/diffusers/ko/using-diffusers/write_own_pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 stable diffusion v1.5 모델 경로입니다.\n",
    "SD_PATH = \"/group-volume/sr_edu/AI-Application-Specialist-Vision-Dataset/hf-models/stable-diffusion-v1-5\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# diffusers 에서 제공하는 pipeline을 이용하여 text to image pipeline을 생성합니다\n",
    "# 시간이 걸립니다.\n",
    "pipe = StableDiffusionPipeline.from_pretrained(SD_PATH)\n",
    "pipe = pipe.to(device)\n",
    "print(f\"Stable Diffusion v1.5 has been loaded on {device} device\")\n",
    "\n",
    "seed = 12345\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 구조\n",
    "- Stable Diffusion 은 크게 CLIP, UNet, VAE라는 세 가지 인공신경망으로 구성되어 있습니다.\n",
    "  - CLIP: 텍스트 입력을 토큰으로 변환\n",
    "  - UNet: 토큰을 기반으로 무작위로 생성된 노이즈를 디노이징하여 이미지 Latent 를 생성\n",
    "  - VAE: Pixel Space 를 Latent Space 를 만드는 인코더와 이것을 Pixel Space 로 되돌리는 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./images/stable_diffusion.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!ls {SD_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지를 생성해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to Image 에 사용할 프롬프트를 pipeline에 넣어주고 이미지 결과를 받습니다.\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to Image 에 사용할 프롬프트를 pipeline에 넣어주고 이미지 결과를 받습니다.\n",
    "prompt = \"a photo of an astronaut riding a horse on mars by Van Gogh\"\n",
    "pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프롬프트 엔지니어링\n",
    "- 프롬프트를 잘 만드는 것은 원하는 이미지를 얻기 위해 가장 기본이 되는 step 입니다.\n",
    "- 프롬프트를 잘 만들기 위해서…\n",
    "  - 기존 프롬프트를 재활용 해보기 \n",
    "    - [civitai.com](https://civitai.com/images), [openart.ai](https://openart.ai/discovery) 와 같은 생성형 이미지 공유사이트를 참고하기\n",
    "  - chatGPT 를 사용해서 프롬프트 만들어보기\n",
    "  - openart.ai에서 만든 [프롬프트 북](https://cdn.openart.ai/assets/Stable%20Diffusion%20Prompt%20Book%20From%20OpenArt%2011-13.pdf) 읽어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 텍스트 프롬프트를 작성하고 이미지를 생성해보세요.\n",
    "prompt = \n",
    "pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable diffusion 파라미터들\n",
    "\n",
    "- 위에처럼 간단하게 pipe(prompt)로 이미지를 생성할 수 있지만, 기본 파라미터 외에도 조정할 수 있는 다양한 파라미터가 있습니다.\n",
    "- 종류 및 설명\n",
    "  - prompt: T2I에 사용할 텍스트 프롬프트\n",
    "  - height, width: 생성할 이미지 사이즈\n",
    "  - num_inference_steps: 몇번의 inference step을 진행 할 것인가. 낮을수록 낮은 퀄리티\n",
    "  - guidance scale: text prompt로 guide를 주는 정도. 낮을수록 텍스트와 거리가 있는 이미지가 생성 될 수 있음. 높을수록 텍스트 반영도가 높음\n",
    "  - num_images_per_prompt: 한 번에 몇 장 생성할지\n",
    "  - generator: seed를 주어 deterministic하게 생성할 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 파라미터 셋팅\n",
    "st = time.time()\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    num_inference_steps=50,\n",
    "    guidance_scale=7.5,\n",
    "    num_images_per_prompt=1,\n",
    "    generator=torch.Generator(device).manual_seed(seed),\n",
    ").images[0]\n",
    "print(time.time()-st)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_inference_step을 줄여보자\n",
    "st = time.time()\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    num_inference_steps=10,\n",
    "    guidance_scale=7.5,\n",
    "    num_images_per_prompt=1,\n",
    "    generator=torch.Generator(device).manual_seed(seed),\n",
    ").images[0]\n",
    "print(time.time()-st)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_inference_step을 줄여보자\n",
    "st = time.time()\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    height=512, \n",
    "    width=512, \n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5,\n",
    "    num_images_per_prompt=1,\n",
    "    generator=torch.Generator(device).manual_seed(seed),\n",
    ").images[0]\n",
    "print(time.time()-st)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 예시처럼, 경우에 맞게 파라미터를 조정 할 수 있습니다.\n",
    "  - 빠르게 샘플링해서 경향성을 봐야하는 경우 30 steps 으로도 충분할 수 있습니다.\n",
    "  - 좋은 퀄리티의 이미지를 얻기 위해서는 default 값인 50 steps를 권장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSFW (Not safe for work) 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"naked\"\n",
    "pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하지만 완벽하진 않아서, NSFW 가 아닐 것임에도 NSFW로 검출되는 경우가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\n",
    "    prompt=\"Mark Zuckerberg\",\n",
    "    height=512,\n",
    "    width=512,\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5,\n",
    "    num_images_per_prompt=1,\n",
    "    generator=torch.Generator(device).manual_seed(seed),\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NSFW 우회하는 방법\n",
    "1. 일시적으로 우회가 필요한 것이라면, pil image로 결과를 받는 것이 아닌 latent 형태로 결과를 받는다.\n",
    "2. 아예 NSFW 가 필요 없다면, 처음 모델을 로드할 때 requires_safety_check를 해제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 일시적으로 우회가 필요한 것이라면, pil image로 결과를 받는 것이 아닌 latent 형태로 결과를 받는다.\n",
    "\n",
    "latents = pipe(\n",
    "    prompt=\"Mark Zuckerberg\",\n",
    "    height=512,\n",
    "    width=512,\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5,\n",
    "    num_images_per_prompt=1,\n",
    "    generator=torch.Generator(device).manual_seed(seed),\n",
    "    output_type=\"latent\",\n",
    ").images\n",
    "\n",
    "image = pipe.vae.decode(\n",
    "    latents / pipe.vae.config.scaling_factor, return_dict=False\n",
    ")[0]\n",
    "do_denormalize = [True] * image.shape[0]\n",
    "image = pipe.image_processor.postprocess(\n",
    "    image.detach(), output_type=\"pil\", do_denormalize=do_denormalize\n",
    ")[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 아예 NSFW 가 필요 없다면, 처음 모델을 로드할 때 requires_safety_check를 해제한다.\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(SD_PATH, requires_safety_checker=False, safety_checker=None, low_cpu_mem_usage=False)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "print(f\"Stable Diffusion v1.5 has been loaded on {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\n",
    "    prompt=\"Mark Zuckerberg\",\n",
    "    height=512,\n",
    "    width=512,\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5,\n",
    "    num_images_per_prompt=1,\n",
    "    generator=torch.Generator(device).manual_seed(seed),\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_torch2i",
   "language": "python",
   "name": "venv_torch2i"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

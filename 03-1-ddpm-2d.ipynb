{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262b757b",
   "metadata": {},
   "source": [
    "# DDPM for 2 dimensional data space\n",
    "## - DDPM: Denoising Diffusion Probabilistic Model\n",
    "\n",
    "- 목표: 2 차원 데이터를 사용하여 DDPM의 Diffusion Process 개념을 이해해 본다.\n",
    "\n",
    "- Reference\n",
    " * Code : [1-d DDPM](https://github.com/stefanoscotta/1-d-generative-diffusion-model)\n",
    " * Paper: [Understanding and contextualizing diffusion models, 2023](https://arxiv.org/pdf/2302.01394)\n",
    " * [Annotated-diffusion](https://huggingface.co/blog/annotated-diffusion)\n",
    "\n",
    "\n",
    "### Prerequisite\n",
    "- install seaborn tqdm\n",
    "```\n",
    "!pip install seaborn  \n",
    "!pip install tqdm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55ca729",
   "metadata": {},
   "source": [
    "### 순서 sketch\n",
    "1. Data Preparation: X0 (Nx2), N x0's \n",
    "  - 원 x0의 2차원 데이터 분포로부터 sample N개를 준비한다.\n",
    "  - 여기서 x0의 2차원 데이터 분포는 Gaussian 분포을 사용한다. \n",
    "  \n",
    "2. DDPM - forward noising process\n",
    "  - noise scheduler: T steps, beta(1), beta(T) --> beta(t)\n",
    "    * alpha(t), alpha_bar(t)\n",
    "    * visualize beta(t), alpha(t), alpha_bar(t)\n",
    "    * check: SNR(T), alpha_bar(T)\n",
    "  - x0 sampling: x0 ~ q(x0) (원본 데이터의 확률 분포)\n",
    "  - forward noising process for given x0: q(x(t)|x0)\n",
    "    * samples for training\n",
    "    * visualize : trajectory w/ animation\n",
    "       - xt_mean\n",
    "    * x(T) distribution: N(0,1**2)\n",
    "\n",
    "(참조) 3. DDPM - reverse denoising proces: p_theta(x(t-1)|x(t))\n",
    "  - models to be trained, train samples \n",
    "  - q(x(t-1)|x(t), x0) ~ p(x(t-1)|x(t))\n",
    "  - Loss, Network design(UNet)\n",
    "    * mean\n",
    "    * eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0208237",
   "metadata": {},
   "source": [
    "### dataframe 사용한 data 저장 및 처리\n",
    "1. X0: N x 2 (n=0,...,N-1)\n",
    "   - x0: 2 x 1 (or 1x2)\n",
    "   - N개 x0 (2차원 데이터)\n",
    "2. Noise scheduler (beta_t, alpha_t, alpha_bar_t): Tx1\n",
    "   - t: (0,) 1,...,T (T+1)\n",
    "   - df_ns (noise scheduler) [t] = [beta, alpha, alpha_bar, sqrt_alpha_bar]\n",
    "3. Xt: N x 2 \n",
    "   - xt: 2 x 1 (or 1x2)\n",
    "   - X0, X1,...,XT: (T+1) x (N x 2)\n",
    "   - x(n, t, d=2): N x (T+1) x 2\n",
    "     df_Xt [n, t, d] = [xt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6bc827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import random as rd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# animation\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Gaussian Mixture Models\n",
    "from sklearn import mixture\n",
    "# to generate isotropic Gaussian blobs \n",
    "from sklearn.datasets import make_blobs\n",
    "# handling data using pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93ca5b",
   "metadata": {},
   "source": [
    "## 1. Data Generation \n",
    "### 1) 2d Data Generation using Gaussian Mixture Models (GMM)\n",
    "\n",
    "2차원 공간상의 2개의 gaussian 분포가 있는 데이터를 만듭니다.\n",
    "- (x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_centers = 2\n",
    "means =[[-5,-5],[5,5]] # 중심 위치(mean) 2개 \n",
    "cluster_std = [0.4, 0.5] # 각각의 표준 편차\n",
    "sample_size = [100, 200] # 각 gaussian의 sample의 갯수\n",
    "\n",
    "# gaussian blobs with labels\n",
    "X, y_true = make_blobs(n_samples=sample_size, \n",
    "                       centers=means, cluster_std=cluster_std, # 2d means, standard deviations \n",
    "                       n_features=2, # 2 dimensional data\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d54150",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, X.dtype, y_true.shape, y_true.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34713a",
   "metadata": {},
   "source": [
    "### 2) Visualize the generated 2d data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f948b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np to dataframe df_X0\n",
    "df_X0= pd.DataFrame({'d1':X[:,0], 'd2':X[:,1]})\n",
    "df_X0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot x0 distribution\n",
    "sns.histplot(df_X0, x='d1', y='d2', stat=\"density\", bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the np data to pytorch tensor X0 (torch.tensor, gpu)\n",
    "X0 = torch.tensor(X).to(torch.float32).to(device)      # to torch \n",
    "N = X0.shape[0]\n",
    "print(X0.shape, N) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014902fb",
   "metadata": {},
   "source": [
    "## 2. DDPM - forward noising process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57783d85",
   "metadata": {},
   "source": [
    "### 1) Noise Scheduling\n",
    "- DDPM의 beta-linear noise scheduler에 따라 noise scheduling을 한다\n",
    "- 입력: $T, \\beta_1, \\beta_T$ \n",
    "- 출력: $\\beta_t, \\alpha_t, \\overline \\alpha_t$ for any $t \\in \\{1,\\dots, T\\}$\n",
    "- DDPM 예: T=1000, $\\beta_1=0.0001, \\beta_T=0.02$\n",
    "- (특히 작은 dataset일 경우) 실험적으로 잘 선정하여야 함. (T는 무한대가 아님)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_beta_noise_scheduler(timesteps=1000, beta_start=0.0001, beta_end=0.02, device='cuda'):\n",
    "    # noise schedule\n",
    "    # the betas grows linearly from beta1 to betaT\n",
    "    # beta(t) = (beta_T - beta_1)/(T-1) * (t-1) + beta_1, t = 1:T\n",
    "\n",
    "    betas = torch.linspace(beta_start, beta_end, timesteps, dtype= torch.float32).to(device) \n",
    "    alphas = 1 - betas \n",
    "    alpha_bars = torch.cumprod(alphas, axis=0).to(torch.float32).to(device)\n",
    "    \n",
    "    return betas, alphas, alpha_bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c70daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise scheduler: linear-beta \n",
    "# - T=1000, 0.0001, 0.02 (DDPM)\n",
    "# - T=1000 steps, \n",
    "\n",
    "# DDPM - original setting\n",
    "T = 1000; beta_1 = .0001; beta_T = .02\n",
    "\n",
    "# parameters\n",
    "# T = 500; beta_1 = .0004;  beta_T = .06\n",
    "\n",
    "# for simple test\n",
    "#T = 10; beta_1 = .02; beta_T = .3\n",
    "\n",
    "# noise schedule\n",
    "betas, alphas, alpha_bars = linear_beta_noise_scheduler(timesteps=T, beta_start=beta_1, beta_end=beta_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2aec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas[0], betas[-1], betas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3111755",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.linspace(1,T,T, endpoint=True)\n",
    "fig = plt.figure(figsize = (13, 5))\n",
    "ax = fig.subplots(1, 2)\n",
    "ax1 = ax[0]\n",
    "ax2 = ax[1]\n",
    "ax1.plot(t, betas.cpu(), label=r'$\\beta$') # raw string for Latex formatted display\n",
    "ax1.plot(t, alphas.cpu(), label=r'$\\alpha$')\n",
    "ax1.plot(t, alpha_bars.cpu(), label=r'$\\bar{\\alpha}$')\n",
    "ax1.plot(t, np.sqrt(alpha_bars.cpu()), label=r'$\\sqrt{\\bar{\\alpha}}$')\n",
    "ax1.plot(t, np.sqrt(1-alpha_bars.cpu()), label=r'$\\sqrt{1-\\bar{\\alpha}}$')\n",
    "ax1.set_xlabel('t')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(t, betas.cpu(), label=r'$\\beta$')\n",
    "ax2.set_xlabel('t')\n",
    "ax2.set_ylabel(r'$\\beta$')\n",
    "ax2.set_title(r'$\\beta_t$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc63e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_c = np.sqrt(alpha_bars.cpu())\n",
    "noise_c = np.sqrt(1-alpha_bars.cpu())\n",
    "signal_c[-5:],noise_c[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR도 정의하고 그려본다\n",
    "SNR = np.sqrt(alpha_bars.cpu())/np.sqrt(1-alpha_bars.cpu())\n",
    "plt.loglog(t, SNR)\n",
    "plt.title(f'SNR(SNR(T)={SNR[-1]:.5f} ~? 0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c48f6",
   "metadata": {},
   "source": [
    "### 2) Forward \"noising\" process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c124d2d",
   "metadata": {},
   "source": [
    "### 1. q_forward_conditional 함수를 정의한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a647c45",
   "metadata": {},
   "source": [
    "- q_forward_conditional은 q 분포에 의해 주어진 $x_{t-1}$에서 $x_t$의 확률 분포\n",
    "- $x_t$ ~ $ q(x_t|x_{t-1}) = N(\\mu , \\sigma^2)$, where $\\mu = \\sqrt{1- \\beta_t} x_{t-1} , \\sigma = \\sqrt{ \\beta_t}$ \n",
    "  * $0 < \\beta_1 < \\beta_2 < ... < \\beta_T < 1$\n",
    "- 표준 정규 분포를 이용하여 $ q(x_t|x_{t-1})$에서 표본을 추출하는 식: $x_t=\\sqrt{1 - \\beta_t} x_t + \\sqrt{\\beta_t}\\epsilon$ \n",
    "  * $\\epsilon$ ~ $N(0 , 1^2)$ (표준 정규 분포)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7579c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate xt seq using conditional distribution with beta parameter\n",
    "# x_0 : x0,  with (d1, d2): 2-dimentional data\n",
    "# return x_t: T+1 sequence (T+1) x 2)\n",
    "# q_forward_beta\n",
    "def q_forward_cond(x_0, betas, device):\n",
    "    t_len = betas.shape[0]\n",
    "    xt_seq = torch.zeros((t_len+1, 2)).to(device)  # (T+1)x2\n",
    "    eps = torch.normal(mean=0, std=1, size=(T,2)).to(device) # Tx2, N(0,1) noise\n",
    "    \n",
    "    xt_seq[0,:] = x_0\n",
    "    for t in range(T):\n",
    "        mean = torch.sqrt(1-betas[t]).to(device)*xt_seq[t] # 2d mean\n",
    "        noise = torch.sqrt(betas[t]) * eps[t,:] # 2d covariance \n",
    "        xt_seq[t+1, :] = mean + noise\n",
    "    return xt_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ecb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 index에 있는 x0를 선택하여 conditional probability에 따라 forward noising process T-step 수행 \n",
    "x0_idx = 1\n",
    "Xt_b = q_forward_cond(X0[x0_idx,:], betas, device)\n",
    "Xt_b_np = Xt_b.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Xt_b_np[:,0], Xt_b_np[:,1],'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea62afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "#%matplotlib inline\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ea85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# animation\n",
    "# num: an input frame number\n",
    "def animate_xt_seq_update(num, ax_, Q, xt_seq, title):\n",
    "    ax_.set_title(f'f{num}')\n",
    "    if num >=1:    \n",
    "        tt = num - 1\n",
    "        uu = xt_seq[1:num+1,0] - xt_seq[:num,0]\n",
    "        vv = xt_seq[1:num+1,1] - xt_seq[:num,1]\n",
    "        Q.set_UVC = ax_.quiver(xt_seq[:num,0], xt_seq[:num,1], uu, vv, color='green', scale_units='xy',scale=1, angles='xy')\n",
    "        ax_.set_title(f'[{title}]t{num}/{xt_seq.shape[0]}: at ({xt_seq[num-1,0]:.2f}, {xt_seq[num-1,1]:.2f}), {len(uu)}')   \n",
    "    elif num == 0:\n",
    "        ax_.cla()\n",
    "        ax_.plot(xt_seq[:,0], xt_seq[:,1],'b-.')\n",
    "        uu = xt_seq[1:,0] - xt_seq[:-1,0]\n",
    "        vv = xt_seq[1:,1] - xt_seq[:-1,1]\n",
    "        Q.set_UVC = ax_.quiver(xt_seq[:-1,0], xt_seq[:-1,1], uu, vv, color='gray', scale_units='xy',scale=1, angles='xy')\n",
    "        ax_.set_title(f'[{title}]t{num}: at ({xt_seq[0,0]:.2f}, {xt_seq[0,1]:.2f}), {len(xt_seq[:-1,0])}')    \n",
    "    return (Q,)\n",
    "\n",
    "def plot_xt_seq(xt_seq, bounds, title='DDPM-forword Animation'):\n",
    "    t_len = xt_seq.shape[0]-1\n",
    "    X = xt_seq[:-1,0] \n",
    "    Y = xt_seq[:-1,1] \n",
    "    u = xt_seq[1:,0] - xt_seq[:-1,0]\n",
    "    v = xt_seq[1:,1] - xt_seq[:-1,1]\n",
    "    fig, ax = plt.subplots(figsize = (7, 7))\n",
    "    ax.plot(xt_seq[:,0], xt_seq[:,1] ,'b-')\n",
    "    Q = ax.quiver(X, Y, u, v, scale_units='xy',scale=1, angles='xy', color='gray') # animated=False\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    ax.axis('equal')\n",
    "    ax.set_xlim(bounds[0,0], bounds[0,1])\n",
    "    ax.set_ylim(bounds[1,0], bounds[1,1])\n",
    "\n",
    "    anim = FuncAnimation(fig, animate_xt_seq_update, fargs=(ax, Q, xt_seq, title), frames=range(0, t_len+1), interval=30, blit=True)\n",
    "\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "Xt_b = q_forward_cond(X0[idx,:],betas, device)\n",
    "bounds = np.array([[-10,10],[-10,10]])\n",
    "Xt_b_np = Xt_b.cpu().detach().numpy(force=True)\n",
    "anim2d_beta = plot_xt_seq(Xt_b_np, bounds, \"DDPM-Forward-1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a68a01",
   "metadata": {},
   "source": [
    "### 2. q_forward 함수를 정의한다. \n",
    "- q_forward는 $\\overline \\alpha$ 파라미터로 표현된 조건부 확률 분포에 의해 주어진 $x_0$에서 $x_t$로의 확률 분포\n",
    "- $x_t(x_0)$ ~ $ q(x_t|x_0) = N(\\mu_t , \\sigma_t ^2)$, where $\\mu_t = \\sqrt{\\overline \\alpha_t} x_0 , \\sigma_t = \\sqrt{1-\\overline \\alpha_t}$\n",
    "- 정규 확률 분포를 사용하여 데이터 샘플링 식: $x_t =\\sqrt{\\overline \\alpha_t} x_0 + \\sqrt{1-\\overline \\alpha_t}\\epsilon$ \n",
    "  * where $\\epsilon$ ~ $N(0 , 1^2)$\n",
    "- (참조) q_forward는 q_forward_conditional 함수에서 유도되는 동등한(equivalent) $x_t$ 분포를 표현함.  </br>\n",
    "  차이점은 q_forwad_conditional는 $x_t$ sampling에 t step 필요한데 반해, q_forward는 1 step으로 sampling 가능함\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_0 : x0 (1x2 torch tensor, with (d1, d2))\n",
    "# return x_t: T sequenced data ((T+1) x 2)\n",
    "def q_forward(x_0, bar_alphas, device):\n",
    "    t_len = bar_alphas.shape[0]\n",
    "    xt_seq = torch.zeros((t_len+1, 2)).to(device) \n",
    "    means = torch.sqrt(bar_alphas).reshape(-1,1)*x_0.reshape(1,-1)\n",
    "    eps = torch.distributions.MultivariateNormal(torch.zeros(2), torch.eye(2)).sample([t_len]).to(device) # sampling from normal distribution\n",
    "    xt_seq[0,:] = x_0\n",
    "    xt_seq[1:,:] = means + torch.sqrt(1-bar_alphas).reshape(-1,1) * eps\n",
    "    return xt_seq\n",
    "\n",
    "# X_0 : N개 x0 (Nx2 torch tensor, with (d1, d2))\n",
    "# return Xt_sequence: N samples (N x (T+1) x 2)\n",
    "def q_forward_array(X_0, bar_alphas, device):\n",
    "    n_len = X_0.shape[0]\n",
    "    t_len = bar_alphas.shape[0]\n",
    "    Xt_seq = torch.zeros((n_len, t_len+1, 2))\n",
    "        \n",
    "    for n, xx_0 in enumerate(X_0[:,:]):\n",
    "        Xt_seq[n, :] = q_forward(xx_0, bar_alphas, device)\n",
    "    return Xt_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 # index : 0~(N-1)중의 임의의 index 선택\n",
    "Xt_a = q_forward(X0[idx,:], alpha_bars, device) # 선택된 x0에 대해 q_forward 로 x_t 샘플 trajectory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_a.device, Xt_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93623090",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff205f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Xt_a.shape)\n",
    "Xt_a_np = Xt_a.detach().cpu().numpy()\n",
    "plt.plot(Xt_a_np[:,0], Xt_a_np[:,1],'b.') #'b.-'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926e3348",
   "metadata": {},
   "source": [
    "$q(x_0)$가 시간이 따라 이동하는 분포를 그려보자. \n",
    "\n",
    "$q(x_T) \\sim \\mathcal{N}(0,1)$ 인지 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select n_samples of x0 from x0 array\n",
    "# and return generated xt[1...T] list for the sampled x0's\n",
    "# output(return) :\n",
    "#  - df_x : x0에 대한 xt trajectory\n",
    "#  - idx_xs : X0에서 랜덤 선택된 x0 index list [0,...,N-1] 의 n_samples 갯수\n",
    "#  - idx_ts : time-step index [0, ..., T] (0 포함 주의)\n",
    "def generate_ddpm_forward_samples(X_0, n_samples, bar_alphas, device, timestep=1):\n",
    "    # X0에서 n_samples개 선택 (ex: 20 개 sample)\n",
    "    n_len=X_0.shape[0] # \n",
    "    t_len=bar_alphas.shape[0]\n",
    "    \n",
    "    idx_xs = [rd.randrange(0, n_len-1) for j in range(n_samples)]\n",
    "    # assign x0 first,\n",
    "    tt=[0, *range(1,t_len+1,timestep)] # T > 1\n",
    "    t_samples = len(tt) # T/step # list_bar_alphas[0] + x0\n",
    "    idx_ts = tt\n",
    "    idx = np.zeros((2, n_samples * t_samples), dtype=np.int32) # time 0  : 20\n",
    "    \n",
    "    xt_data = q_forward_array(X_0[idx_xs,:], alpha_bars, device).cpu().detach().numpy().reshape(-1,2)\n",
    "        \n",
    "    for n in range(n_samples):\n",
    "        idx[0, n * t_samples:(n+1) * t_samples] = np.array(tt, dtype=np.int32) # time index\n",
    "        idx[1, n * t_samples:(n+1) * t_samples] = np.full((1,t_samples), idx_xs[n]) # x sample index\n",
    "    \n",
    "    df_x = pd.DataFrame(xt_data, columns=['d1', 'd2'])\n",
    "    df_x['t'] = idx[0]\n",
    "    df_x['x0_idx'] = idx[1]\n",
    "    \n",
    "    return df_x, idx_xs, idx_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551af64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T가 길고, sample수가 증가하면 시간이 많이 걸림\n",
    "# X0에서 n_sample 갯수의 x0를 선택, 이 x0들에 대해 q_forward trajectory를 얻음\n",
    "# \n",
    "df_Xt, idx_xs, idx_ts = generate_ddpm_forward_samples(X0, n_samples=200, bar_alphas=alpha_bars, device=device, timestep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ac33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0의 특정 sample 하나를 선택해서 x(t) trajectory plot\n",
    "idx2 = 1 # selet a random x0 index for plotting\n",
    "df_Xt[(df_Xt['x0_idx'] == idx_xs[idx2]) & (df_Xt['t'] == 0) ][['d1','d2']] # (d1, d2) for the selected x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48843db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(10,10))\n",
    "df_Xt[df_Xt['x0_idx'] == idx_xs[idx2]][['d1','d2','t']].plot.line(x='d1',y='d2', ax=axes[0,0])\n",
    "df_Xt[df_Xt['x0_idx'] == idx_xs[idx2]][['t','d1','d2']].reset_index().set_index('t')[['d1','d2']].plot.line(ax=axes[0,1])\n",
    "df_Xt[df_Xt['x0_idx'] == idx_xs[idx2]][['d1','d2','t']].plot.scatter(x='d1',y='d2',c='t', colormap='viridis', ax=axes[1,0])\n",
    "df_Xt[df_Xt['t'] == T-1][['d1','d2']].plot.scatter(x='d1',y='d2', ax=axes[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e6150",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12,7))\n",
    "df_Xt[['d1','d2','t']].plot.scatter(x='d1',y='d2',c='t', colormap='viridis', ax=axes[0]) # xt 전체에 대해 xt trajectory data plot\n",
    "df_Xt[df_Xt['x0_idx'] == idx_xs[idx2]][['t','d1','d2']].plot.scatter(x='d1',y='d2',c='t', colormap='viridis', ax=axes[1]) # 특정 선택된 x0에 대한 xt plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7938aea2",
   "metadata": {},
   "source": [
    "### t에 따른 xt 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t step에 따른 분포 이동 가시화\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, sharex=True, figsize=(15,8))\n",
    "fig.suptitle(r'$x_t$ distribution vs time', fontsize=16)\n",
    "\n",
    "#t_list = [0, 101, 201, 301, 401, 499] # 특정 보고자 하는 t step list\n",
    "t_list = [int(x*T) for x in [0, 0.2, 0.4, 0.6, 0.8, 1]] # 일정 간격 t step 선택\n",
    "t_list = [x if x < T else T for x in t_list]\n",
    "\n",
    "for i, t_ in enumerate(t_list):\n",
    "    m = i//3\n",
    "    n = i%3\n",
    "    \n",
    "    axes[m][n].hist2d(df_Xt[df_Xt['t'] == t_]['d1'], df_Xt[df_Xt['t'] == t_]['d2'], bins=(100,100), range=((-6,6),(-6,6)), cmap=plt.cm.viridis )\n",
    "    axes[m][n].set_xlim([-6, 6])\n",
    "    axes[m][n].set_ylim([-6, 6])\n",
    "    axes[m][n].set_title(f't={t_}', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b5a16",
   "metadata": {},
   "source": [
    "### Animation: t에 따른 xt의 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666dcfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "#%matplotlib inline\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625be1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num: an input frame number\n",
    "def update2d_ddpm_forward(num, df_xt, im, ax, title=None):\n",
    "    #if num < 1:\n",
    "    #    return (P1, P2)\n",
    "    if num > 1:\n",
    "        t_=num\n",
    "    else:\n",
    "        t_=1\n",
    "        \n",
    "    ax.clear()\n",
    "    xedges = np.linspace(bounds[0,0], bounds[0,1],100)\n",
    "    yedges = np.linspace(bounds[1,0], bounds[1,1],100)    \n",
    "    x = df_xt[df_xt['t'] == t_]['d1']\n",
    "    y = df_xt[df_xt['t'] == t_]['d2']\n",
    "    hist, xedges, yedges = np.histogram2d(x, y, [xedges, yedges])\n",
    "    if len(hist) == 0:\n",
    "        print (f't_={t_}')\n",
    "        ax.set_title(f't={t_},hist_N={len(hist)}', fontsize=16)\n",
    "        return \n",
    "    xidx = np.clip(np.digitize(x, xedges)-1, 0, hist.shape[0]-1)\n",
    "    yidx = np.clip(np.digitize(y, yedges)-1, 0, hist.shape[1]-1)\n",
    "    c = hist[xidx, yidx]\n",
    "    im = ax.scatter(x, y, c=c)\n",
    "    ax.set_xlim([bounds[0,0], bounds[0,1]])\n",
    "    ax.set_ylim([bounds[1,0], bounds[1,1]])\n",
    "    ax.set_title(f't={t_},hist_N={len(hist)}', fontsize=16)\n",
    "    plt.show()\n",
    "    return im \n",
    "\n",
    "def plot_ddpm_forward_anim(df_xt, title, bounds, interval=100, blit=True, repeat=True):\n",
    "    \"\"\"\n",
    "    Plots the solutions along with the objective function's contour plot.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df_xt (dataframe): np array containing the xt and x0 \n",
    "    title (str): The title of the plot.\n",
    "    bounds (numpy array): A 2x2 numpy array containing the lower and upper bounds\n",
    "                          of the input variables. The first row should contain the\n",
    "                          bounds for the first input variable, and the second row\n",
    "                          should contain the bounds for the second input variable.\n",
    "    interval: interval in animation update \n",
    "    blit: update partial region if blit=True\n",
    "    repeat: repeat display if True, otherwise once display\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "        \n",
    "    # sample input range uniformly at 0.1 increments\n",
    "    xaxis = np.arange(bounds[0,0], bounds[0,1], 0.1)\n",
    "    yaxis = np.arange(bounds[1,0], bounds[1,1], 0.1)\n",
    "    \n",
    "    # create a mesh from the axis\n",
    "    # compute targets\n",
    "    \n",
    "    fig = plt.figure(figsize = (5, 5))\n",
    "    ax = fig.subplots(1, 1)\n",
    "    \n",
    "    # figure : plot xt vs time\n",
    "    # create a filled contour plot with 50 levels and jet color scheme\n",
    "    # plot the sample as black circles\n",
    "    t_ = 0\n",
    "    xedges = np.linspace(bounds[0,0], bounds[0,1],100)\n",
    "    yedges = np.linspace(bounds[1,0], bounds[1,1],100)    \n",
    "    x = df_xt[df_xt['t'] == t_]['d1']\n",
    "    y = df_xt[df_xt['t'] == t_]['d2']\n",
    "    hist, xedges, yedges = np.histogram2d(x, y, [xedges, yedges]) \n",
    "    xidx = np.clip(np.digitize(x, xedges)-1, 0, hist.shape[0]-1)\n",
    "    yidx = np.clip(np.digitize(y, yedges)-1, 0, hist.shape[1]-1)\n",
    "    c = hist[xidx, yidx]\n",
    "    im = ax.scatter(x, y, c=c)\n",
    "    \n",
    "    ax.set_xlim([bounds[0,0], bounds[0,1]])\n",
    "    ax.set_ylim([bounds[1,0], bounds[1,1]])\n",
    "    ax.set_title(f't={t_}', fontsize=16)\n",
    "    \n",
    "    # animation\n",
    "    anim = FuncAnimation(fig=fig, func=update2d_ddpm_forward, fargs=(df_xt, im, ax, title), frames=range(1,501,2), \n",
    "                         interval=interval, blit=blit, repeat=repeat)    \n",
    "    \n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # You must store the created animation in a varaible that lives as long as the animation should run\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Xt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range for input\n",
    "# bounds: range for plot \n",
    "bounds = np.array([[-10.0, 10.0], [-10.0, 10.0]])\n",
    "step = 50\n",
    "\n",
    "# Animation for DDPM-2d \n",
    "# to show animation, you must store the returned anim variable\n",
    "anim_gd = plot_ddpm_forward_anim(df_Xt, \"DDPM Forward Trajectory Histogram in 2D\", bounds, interval=50, blit=False, repeat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60563cf5",
   "metadata": {},
   "source": [
    "### 특정 t 시점에서 xt 분포 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f22e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = 301\n",
    "fig = plt.figure(figsize = (7, 7))\n",
    "ax = fig.subplots(1, 1)\n",
    "    \n",
    "xedges = np.linspace(-6,6,100)\n",
    "yedges = np.linspace(-6,6,100)    \n",
    "x = df_Xt[df_Xt['t'] == t_]['d1']\n",
    "y = df_Xt[df_Xt['t'] == t_]['d2']\n",
    "hist, xedges, yedges = np.histogram2d(x, y, [xedges, yedges], range=[[-6,6],[-6,6]]) \n",
    "xidx = np.clip(np.digitize(x, xedges), 0, hist.shape[0]-1)\n",
    "yidx = np.clip(np.digitize(y, yedges), 0, hist.shape[1]-1)\n",
    "c = hist[xidx, yidx]\n",
    "im = ax.scatter(x, y, c=c)\n",
    "\n",
    "ax.set_xlim([-6, 6])\n",
    "ax.set_ylim([-6, 6])\n",
    "ax.set_title(f't={t_}', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707905db",
   "metadata": {},
   "source": [
    "## 참고 - Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8442c",
   "metadata": {},
   "source": [
    "$p(x_0)$분포의 몇개의 샘플에 대해 DDPM forward trajectory를 그려보자.\n",
    "\n",
    "어떠한 임의의 분포 $p(x_0)$든, $p(x_0)$에서 시작하여 시간이 감에 따라서 평균이 $0$인 표준편차가 1인 $\\mathcal{N}(0,1)$ 정규 분포에서 샘플들된 점들로 된 분포로 수렴해 가는 것을 볼 수 있을 것이다.\n",
    "\n",
    "We can also plot some trajectories for some numbers of points of the distribution \n",
    "We'll see that starting from our arbitrary distribution $p(x_0)$ the trajectories converge to some point symmetric with respect to $0$, exactly as the points distributed as a $\\mathcal{N}(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa4fd0",
   "metadata": {},
   "source": [
    "실습 \n",
    "1. 임의의 x0에서 시간 t가 t=1...T까지 변화함에 따라 x_t_mean 평균 위치 이동 (drift) 궤적 그려보기(2d)\n",
    "2. 임의의 x0에서 시간 t가 t=1...T까지 변화함에 따라 x_t_mean 평균 위치 이동 (drift) 및 noise의 표준편차 궤적 그려보기(2d)\n",
    "3. 임의의 x0에서 시간 t에 따라 noise 추가하여 이동한 위치 x_t의 위치 이동 궤적 그려보기(2d)\n",
    "4. 3.에서 여러 x0에 대한 이동 궤적 그려 보고 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ce578",
   "metadata": {},
   "source": [
    "## Diffusion Model Configuration 사용\n",
    "- dm_config 설정후\n",
    "- init_dm_config 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07841b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm_config : Diffusion Model Configuration\n",
    "# init noise scheduler\n",
    "def init_dm_config(dm_config):\n",
    "    beta_1 = dm_config['beta_1']\n",
    "    beta_T = dm_config['beta_T']\n",
    "    T = dm_config['T']\n",
    "    \n",
    "    if dm_config[\"scheduler\"] == 'beta-linear':\n",
    "        #the betas grows linearly from beta1 to betaT\n",
    "        betas, alphas, alpha_bars = linear_beta_noise_scheduler(T, beta_1, beta_T)     \n",
    "        \n",
    "    else:\n",
    "        print(\"beta-linear is used for the noise scheduler\")\n",
    "        betas, alphas, alpha_bars = linear_beta_noise_scheduler(T, beta_1, beta_T)     \n",
    "    \n",
    "    dm_config['betas'] = betas\n",
    "    dm_config['alphas'] = alphas\n",
    "    dm_config['alpha_bars'] = alpha_bars\n",
    "    dm_config['t'] = np.concatenate((np.zeros(1, dtype='int'), np.linspace(1, dm_config['T'], dm_config['T'], endpoint=True, dtype='int'))) # (0, 1, 1+t-step, ...)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_config_custom = {\"beta_1\":.0004, \"beta_T\":.06, \"T\":500, 't-step':1, \"scheduler\":\"beta-linear\"}\n",
    "dm_config_ddpm = {\"beta_1\":.0001, \"beta_T\":.02, \"T\":1000, 't-step':1, \"scheduler\":\"beta-linear\"}\n",
    "dm_config = dm_config_ddpm\n",
    "init_dm_config(dm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a553fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_config['alpha_bars'].dtype, dm_config['alpha_bars'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac38bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm_config[\"t\"])\n",
    "tt = dm_config['t'][:-1]\n",
    "alpha_bar_t = dm_config['alpha_bars'][tt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bdb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_forward_xt_mean_std(x_0, t, bar_alphas, device):\n",
    "    alpha_bar_t = bar_alphas[t]\n",
    "    \n",
    "    xt_mean = torch.sqrt(alpha_bar_t).reshape(alpha_bar_t.shape[0],-1)*x_0.reshape(1,-1)\n",
    "    xt_std = torch.sqrt(1-alpha_bar_t) # the same 2d covariance\n",
    "                \n",
    "    return xt_mean, xt_std\n",
    "\n",
    "# from single x0, xt_mean trajectory for t=1, ...T\n",
    "\n",
    "def q_forward_xt_mean_std_array(x_0, device='cpu', **config):\n",
    "    len_data=x_0.shape[0] # x0_n_samples = 20\n",
    "    \n",
    "    T = config['T']\n",
    "    alpha_bars = config['alpha_bars']\n",
    "    t_step = config['t-step']\n",
    "    \n",
    "    tt=range(0, T, t_step) # T > 1\n",
    "    t_samples = len(tt)  # T/step # list_bar_alphas[0] + x0\n",
    "    \n",
    "    xt_means, xt_stds = q_forward_xt_mean_std(x_0, tt, alpha_bars, device)\n",
    "\n",
    "\n",
    "    n_samples = 1 # len(idx_ts)\n",
    "    xt_data = xt_means.cpu().numpy() # 51(t_samples) x 20(n_samples) x 2\n",
    "    xt_std_data = xt_stds.cpu().numpy() # 51(t_samples) x 20(n_samples) x 2\n",
    "    \n",
    "    # to dataframe\n",
    "    df_x = pd.DataFrame(xt_data)\n",
    "    df_x.columns=['m1', 'm2']\n",
    "    df_x['t'] = tt\n",
    "    df_x['std'] = xt_std_data\n",
    "    \n",
    "    return df_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 x_0에 대해 t step에서 xt의 평균 구하기 (xt_mean)\n",
    "x0_idx = 1\n",
    "df_xt_ms = q_forward_xt_mean_std_array(X0[x0_idx], device, **dm_config)\n",
    "len(df_xt_ms), df_xt_ms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cf333",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5359a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for random x0 index\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
    "df_xt_ms[['m1','m2','t']].plot.scatter(x='m1',y='m2',c='t', colormap='viridis', ax=axes[0])\n",
    "df_xt_ms[['m1','m2','t']].plot.line(x='m1',y='m2', ax=axes[1])\n",
    "df_xt_ms[['t','m1','m2']].reset_index().set_index('t')[['m1','m2']].plot.line(ax=axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29146e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n point에 대해 scatter plot (m1, m2), radius = std\n",
    "n = 1000\n",
    "idx = slice(0,n,30)\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "colors = cmap(df_xt_ms['t']/df_xt_ms['t'].shape[0]*255)\n",
    "df_xt_ms['c'] = df_xt_ms['t'].apply(lambda x: cmap(x/df_xt_ms['t'].shape[0]*255))\n",
    "g = plt.scatter(df_xt_ms[['m1']][idx], df_xt_ms[['m2']][idx],s=df_xt_ms[['std']][idx]*1000, marker='o', facecolors='none', edgecolors=df_xt_ms['c'] )\n",
    "g.set_facecolor('none')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546212d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(df_xt_ms.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff82450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "def plot_dm_x0_trajectory(df_xt, step=50):\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for index, row in df_xt.iterrows(): \n",
    "        if index % step != 0:\n",
    "            continue\n",
    "            \n",
    "        x = row['m1']\n",
    "        y = row['m2']\n",
    "        t = row['t']\n",
    "        c = t/T\n",
    "        color = cm.viridis(t/T) # color = cm.jet(t/T)\n",
    "        size = row['std']\n",
    "        \n",
    "        if t > T:\n",
    "            break\n",
    "        circle=plt.Circle((x, y), size, color=color, fill=False)\n",
    "        dot=plt.Circle((x, y), 0.02, color=color, fill=True)\n",
    "        \n",
    "        ax.add_artist(circle)\n",
    "        ax.add_artist(dot)\n",
    "\n",
    "    plt.xlim([-6,7])\n",
    "    plt.ylim([-6,7])\n",
    "    ax.set_aspect(1.0)\n",
    "\n",
    "    if 'm1' in df_xt:\n",
    "        tt = range(0, len(df_xt), step)\n",
    "        plt.plot(df_xt[['m1']].loc[tt], df_xt[['m2']].loc[tt], '.-') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e857889",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idx = 6\n",
    "df_xt_ms = q_forward_xt_mean_std_array(X0[x0_idx], device, **dm_config)\n",
    "\n",
    "plot_dm_x0_trajectory(df_xt_ms, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94355d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_xt_ms.head()), len(df_xt_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c5bfd",
   "metadata": {},
   "source": [
    "# Animation for trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b980940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_0 : N개의 x0 (d1, d2)\n",
    "# return : x0 trajectory [xt] (xt_samples, xt_means, xt_stds)\n",
    "# note: x0 is not included in returned tensors\n",
    "def q_forward_trajectory(x_0, t, bar_alphas, device, including_x0=True):\n",
    "    assert (len(t) <= len(bar_alphas))\n",
    "    \n",
    "    alpha_bar_t = bar_alphas[t]\n",
    "    s = torch.zeros(len(t), x_0.shape[0], device=device)\n",
    "    \n",
    "    xt_means = torch.sqrt(alpha_bar_t).reshape(alpha_bar_t.shape[0],-1)*x_0.reshape(1,-1) # dimension\n",
    "    xt_stds = torch.sqrt(1-alpha_bar_t) # the same 2d covariance\n",
    "    \n",
    "    cov = torch.eye(x_0.shape[0]).to(device) # 2d covariance \n",
    "    \n",
    "    for n, t_ in enumerate(t):\n",
    "        cov2 = cov*(1-alpha_bar_t[n]) # the same 2d covariance\n",
    "        s[n, :] = torch.distributions.MultivariateNormal(xt_means[n,:], cov2).sample().to(device)\n",
    "\n",
    "    # if you want to include x0\n",
    "    if including_x0 == True:\n",
    "        x_0 = torch.tensor(x_0).unsqueeze(0).to(device)\n",
    "        s = torch.cat([x_0, s], axis=0)    \n",
    "        xt_means = torch.cat([x_0, xt_means], axis=0)    \n",
    "        xt_stds = torch.cat([torch.zeros(1, dtype=torch.float32, device=device), xt_stds], axis=0)    \n",
    "\n",
    "    return s, xt_means, xt_stds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  임의로 샘플된 x0(x0_index)에 대한 test\n",
    "x0_idx = 0 # sample index for x0\n",
    "t_step = dm_config['t-step']\n",
    "tt = dm_config['t'][:-1] # 0, ..., T-1 for indexing\n",
    "\n",
    "xt, xt_means, xt_noises = q_forward_trajectory(X0[x0_idx], tt, dm_config['alpha_bars'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c27a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt.shape, xt_means.shape, xt_noises.shape, len(dm_config['t'][:-1]) # excluding last index for t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0bad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt.shape, len(dm_config['t']), xt_means.shape, xt_noises.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2de8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xt2 = pd.DataFrame({'t':dm_config['t'], 'd1':xt[:,0].cpu().numpy(), 'd2':xt[:,1].cpu().numpy(), \n",
    "                       'm1':xt_means[:,0].cpu().numpy(), 'm2':xt_means[:,1].cpu().numpy(), 'std': xt_noises.cpu().numpy()})\n",
    "df_xt2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dm_x0_trajectory(df_xt2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4639a",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec50ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ab142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# - bound 추가, \n",
    "# - 느려짐\n",
    "# num: an input frame number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d359e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update2d_line(num, df_xt, P1, P2, lines, ax, title=None):\n",
    "    if num > 1:\n",
    "        t_=num\n",
    "    else:\n",
    "        t_=1\n",
    "    print(f'update:{num}, t={t_}')\n",
    "    T_ = df_xt.shape[0] \n",
    "    T = T_\n",
    "    xt_1 = df_xt[['d1']].loc[t_]\n",
    "    xt_2 = df_xt[['d2']].loc[t_]\n",
    "    mt_1 = df_xt[['m1']].loc[t_]\n",
    "    mt_2 = df_xt[['m2']].loc[t_]\n",
    "    # figure 1\n",
    "    P1.set_data(df_xt[['d1']].loc[:t_], df_xt[['d2']].loc[:t_]) # P: line\n",
    "    \n",
    "    # figure 2\n",
    "    size = df_xt[['std']].loc[t_]\n",
    "    circle=plt.Circle((mt_1, mt_2), size, color='b', fill=False)\n",
    "    mt_dot=plt.Circle((mt_1, mt_2), 0.02, color='g', fill=True)\n",
    "    xt_dot=plt.Circle((xt_1, xt_2), 0.01, color='r', fill=True)\n",
    "        \n",
    "    ax[0,1].add_artist(circle)\n",
    "    ax[0,1].add_artist(mt_dot)\n",
    "    ax[0,1].add_artist(xt_dot)\n",
    "    \n",
    "    # figure 3\n",
    "    if num == 0:\n",
    "        ax[1,0].cla()\n",
    "    ax[1,0].plot(df_xt[['d1']].loc[:t_], df_xt[['d2']].loc[:t_], '*', color='b') # P=line \n",
    "    \n",
    "    ax[0,0].set_title(f'[xt]t={t_}/{T}') \n",
    "    ax[0,1].set_title(f'[mt]t={t_}/{T}') \n",
    "       \n",
    "    ax[1,0].set_title(f't={t_}/{T}') \n",
    "        \n",
    "    # figure 4 \n",
    "    lines[0].set_data(df_xt[['d1']].loc[:t_], df_xt[['d2']].loc[:t_] )\n",
    "    lines[1].set_data(df_xt[['m1']].loc[:t_], df_xt[['m2']].loc[:t_] )\n",
    "    \n",
    "    ax[1,1].set_title(f't={t_}/{T}, num={num}') \n",
    "    \n",
    "    return (P1, P2, lines)\n",
    "\n",
    "def plot_dm_trajectory_anim_line(df_xt, title, bounds, interval=100, blit=True, repeat=True):\n",
    "    \"\"\"\n",
    "    Plots the solutions along with the objective function's contour plot.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df_xt (dictionary): np array containing the xt and x0 \n",
    "    title (str): The title of the plot.\n",
    "    bounds (numpy array): A 2x2 numpy array containing the lower and upper bounds\n",
    "                          of the input variables. The first row should contain the\n",
    "                          bounds for the first input variable, and the second row\n",
    "                          should contain the bounds for the second input variable.\n",
    "    interval: interval in animation update \n",
    "    blit: update partial region if blit=True\n",
    "    repeat: repeat display if True, otherwise once display\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "        \n",
    "    # sample input range uniformly at 0.1 increments\n",
    "    xaxis = np.arange(bounds[0,0], bounds[0,1], 0.1)\n",
    "    yaxis = np.arange(bounds[1,0], bounds[1,1], 0.1)\n",
    "    \n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    ax = fig.subplots(2, 2)\n",
    "    ax1 = ax[0,0]\n",
    "    ax2 = ax[0,1]\n",
    "    ax3 = ax[1,0]\n",
    "    ax4 = ax[1,1]\n",
    "    \n",
    "    # figure 1 : plot xt vs time\n",
    "    P1, = ax1.plot(df_xt[['d1']], df_xt[['d2']], '.-', color='r') # P=line \n",
    "    ax1.set_title(f'{title}: xt')\n",
    "    ax1.set_xlabel('d1')\n",
    "    ax1.set_ylabel('d2')\n",
    "    ax1.set_xlim(bounds[0,0], bounds[0,1])\n",
    "    ax1.set_ylim(bounds[1,0], bounds[1,1])\n",
    "    \n",
    "    # figure 2: plot mean_t vs time\n",
    "    P2, = ax2.plot(df_xt[['m1']], df_xt[['m2']], '.-', color='g') # P=line \n",
    "    ax2.cla()\n",
    "    ax2.set_title(f'{title}: mt')\n",
    "    ax2.set_xlabel('d1')\n",
    "    ax2.set_ylabel('d2')\n",
    "    ax2.set_xlim(bounds[0,0], bounds[0,1])\n",
    "    ax2.set_ylim(bounds[1,0], bounds[1,1])\n",
    "    ax2.set_aspect(1.0)\n",
    "\n",
    "    # figure 3 : scatter plot for xt    \n",
    "    ax3.plot(df_xt[['d1']], df_xt[['d2']], '*', color='b') # P=line \n",
    "    ax3.cla()\n",
    "    ax3.set_title(f'{title}: xt')\n",
    "    ax3.set_xlabel('d1')\n",
    "    ax3.set_ylabel('d2')\n",
    "    ax3.set_xlim(bounds[0,0], bounds[0,1])\n",
    "    ax3.set_ylim(bounds[1,0], bounds[1,1])\n",
    "    \n",
    "    # figure 4 : x(t)-x(t-1) and mean(t) ~ mean(t-1)\n",
    "    num = 1 # t= 1\n",
    "    t = 10\n",
    "    lines = []\n",
    "    line, = ax4.plot(df_xt[['d1']][t-1:t], df_xt[['d2']][t-1:t], '.-', color='r' )\n",
    "    lines.append(line)\n",
    "    line, = ax4.plot(df_xt[['m1']][t-1:t], df_xt[['m2']][t-1:t], '.-', color='g' )\n",
    "    lines.append(line)\n",
    "    \n",
    "    ax4.set_xlabel('d1')\n",
    "    ax4.set_ylabel('d2')\n",
    "    ax4.set_title('xt and mt')\n",
    "    ax4.set_xlim(bounds[0,0], bounds[0,1])\n",
    "    ax4.set_ylim(bounds[1,0], bounds[1,1])\n",
    "    \n",
    "    # animation\n",
    "    anim = FuncAnimation(fig=fig, func=update2d_line, fargs=(df_xt, P1, P2, lines, ax, title), frames=range(df_xt.shape[0]), interval=interval, blit=blit, repeat=repeat)    \n",
    "\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # You must store the created animation in a variable that lives as long as the animation should run\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac529ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range for input\n",
    "# bounds: range for plot \n",
    "bounds = np.array([[-10.0, 10.0], [-10.0, 10.0]])\n",
    "step = 50\n",
    "\n",
    "# Animation for DDPM-2d \n",
    "# to show animation, you must store the returned anim variable\n",
    "anim_gd = plot_dm_trajectory_anim_line(df_xt2, \"DDPM Trajectory in 2D\", bounds, interval=1, blit=True, repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc085793",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad59f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_torch2i",
   "language": "python",
   "name": "venv_torch2i"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

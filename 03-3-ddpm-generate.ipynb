{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48be7ce9",
   "metadata": {},
   "source": [
    "## DDPM Generate an image using Diffusers \n",
    "\n",
    "- Reference [diffusers_intro](https://github.com/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb), [training_example](https://github.com/huggingface/notebooks/blob/main/diffusers/training_example.ipynb)\n",
    "- Requirements: diffusers, pytorch \n",
    "\n",
    "### Installation\n",
    "- Install `!pip install diffusers==0.11.1`\n",
    "- Install `!pip install accelerate`  \n",
    "  if you see the following message    \n",
    "  ```\n",
    "  Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
    "    - Install `pip install diffusers[training]==0.11.1\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as DisplayImage\n",
    "\n",
    "from diffusers import DDPMPipeline\n",
    "\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a4cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/group-volume/sr_edu/AI-Application-Specialist-Vision-Dataset/'\n",
    "\n",
    "DisplayImage(filename=dataset_path  + 'hf-assets/ddpm_paper.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to download models from huggingface, it is necessary to set the following proxy and ssl \n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# suwon\n",
    "import os\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = '/etc/ssl/certs/ca-certificates.crt'\n",
    "os.environ['HTTP_PROXY'] ='http://75.17.107.42:8080'\n",
    "os.environ['HTTPS_PROXY'] ='http://75.17.107.42:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0cf4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "hf_model_dir = dataset_path + \"hf-models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e789f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm_pipe = DDPMPipeline.from_pretrained(hf_model_dir+\"google/ddpm-cat-256\")\n",
    "#ddpm_pipe = DDPMPipeline.from_pretrained(hf_model_dir+\"google/ddpm-celebahq-256\")\n",
    "# directly to download from huggingface \n",
    "#ddpm_pipe = DDPMPipeline.from_pretrained(\"google/ddpm-celebahq-256\")\n",
    "ddpm_pipe.to(device)\n",
    "ddpm_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc825816",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ddpm_pipe().images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d204c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f412936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ae966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel\n",
    "\n",
    "repo_id = hf_model_dir + \"google/ddpm-church-256\"\n",
    "model = UNet2DModel.from_pretrained(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random image at time=T\n",
    "torch.manual_seed(0)\n",
    "\n",
    "noisy_sample = torch.randn(\n",
    "    1, model.config.in_channels, model.config.sample_size, model.config.sample_size\n",
    ")\n",
    "noisy_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noisy_residual = model(sample=noisy_sample, timestep=2).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af66d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler\n",
    "\n",
    "scheduler = DDPMScheduler.from_config(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172dfcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_noisy_sample = scheduler.step(\n",
    "    model_output=noisy_residual, timestep=2, sample=noisy_sample\n",
    ").prev_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad783fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_residual.shape, less_noisy_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "def display_sample(sample, i):\n",
    "    image_processed = sample.cpu().permute(0, 2, 3, 1)\n",
    "    image_processed = (image_processed + 1.0) * 127.5\n",
    "    image_processed = image_processed.numpy().astype(np.uint8)\n",
    "\n",
    "    image_pil = PIL.Image.fromarray(image_processed[0])\n",
    "    display(f\"Image at step {i}\")\n",
    "    display(image_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59630535",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sample(less_noisy_sample,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60368e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "noisy_sample = noisy_sample.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "sample = noisy_sample\n",
    "\n",
    "for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):\n",
    "    # 1. predict noise residual\n",
    "    with torch.no_grad():\n",
    "        residual = model(sample, t).sample\n",
    "\n",
    "    # 2. compute less noisy image and set x_t -> x_t-1\n",
    "    sample = scheduler.step(residual, t, sample).prev_sample\n",
    "\n",
    "    # 3. optionally look at image\n",
    "    if (i + 1) % 50 == 0:\n",
    "        display_sample(sample, i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8add83",
   "metadata": {},
   "source": [
    "### DDIM Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMScheduler\n",
    "\n",
    "scheduler = DDIMScheduler.from_config(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.set_timesteps(num_inference_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a02101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "sample = noisy_sample\n",
    "\n",
    "for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):\n",
    "    # 1. predict noise residual\n",
    "    with torch.no_grad():\n",
    "        residual = model(sample, t).sample\n",
    "\n",
    "    # 2. compute previous image and set x_t -> x_t-1\n",
    "    sample = scheduler.step(residual, t, sample).prev_sample\n",
    "\n",
    "    # 3. optionally look at image\n",
    "    if (i + 1) % 10 == 0:\n",
    "        display_sample(sample, i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03efbb",
   "metadata": {},
   "source": [
    "### cifar10-ddpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b237f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install diffusers\n",
    "from diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90edc68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = hf_model_dir + \"google/ddpm-cifar10-32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49647d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and scheduler\n",
    "ddpm = DDPMPipeline.from_pretrained(model_id)  # you can replace DDPMPipeline with DDIMPipeline or PNDMPipeline for faster inference\n",
    "ddpm = ddpm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c8f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pipeline in inference (sample random noise and denoise)\n",
    "t0 = time.time()\n",
    "image = ddpm().images[0]\n",
    "print(time.time()-t0)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ac996",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddim = DDIMPipeline.from_pretrained(model_id)  # you can replace DDPMPipeline with DDIMPipeline or PNDMPipeline for faster inference\n",
    "ddim = ddim.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pipeline in inference (sample random noise and denoise)\n",
    "t0 = time.time()\n",
    "image = ddim().images[0]\n",
    "print(time.time()-t0)\n",
    "\n",
    "# to save image\n",
    "# image.save(\"ddim_generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613175b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_torch2i",
   "language": "python",
   "name": "venv_torch2i"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
